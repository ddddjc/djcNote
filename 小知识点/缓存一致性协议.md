# 缓存一致性协议

> 1. **JMM 和缓存一致性协议没有一毛钱关系。**
> 2. **JMM 和 MESI 没有一毛钱关系。**
> 3. 补一个层面的东西

> 缓存一致性协议有MSI，MESI，MOSI，Synapse，Firefly及DragonProtocol等等。

## 1.CPU高速缓存

参考：[浅析CPU高速缓存(cache) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/340573903)

[关于缓存一致性协议、MESI、StoreBuffer、InvalidateQueue、内存屏障、Lock指令和JMM的那点事 - 掘金 (juejin.cn)](https://juejin.cn/post/7109464558783168526#heading-8)

[内存屏障的来历 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/125549632)CPU高速缓存区是位于CPU与内存之间的临时存储器，主要是为了解决CPU运行速度与内存读写速度不匹配之间的矛盾。

CPU在执行指令时需要从内存获取指令和所需的数据，但是CPU的速度要永远大于内存速度，所以CPU直接从内存中存取数据要等待一定的时间周期，造成资源的浪费并且影响性能

这个时候需要引用CPU缓存，现在常见的缓存结构为三级缓存，CPU缓存被分成了三个级别：L1，L2，L3。级别越小越接近CPU，所以速度更快，同时容量也越小。

![img](https://pic4.zhimg.com/80/v2-c1065f9126dd9ea51c252ff86122c1ab_720w.webp)

CPU往往需要重复处理相同的数据、指令，把这部分数据、指令放在CPU缓存中，CPU就不需要从内存区读取数据、指令，从而减少响应时间

> 局部性原理：
>
> - 时间局部性：如果某个数据被访问，那么在不就得将来他很有可能再次被访问
> - 空间局部性：如果某个数据被访问，那么他相邻的数据页很可能被访问

CPU缓存是由一组称之为缓存行（Cache Line）的固定大小的数据块组成的，缓存行是缓存中可以分配的最小存储单位，通常是64字节

引如缓存后，性能得到了提升，但是需要考虑一致性问题

## 2.一致性问题

引入了CPU高速缓存后，提升了效率，但同时也会引发缓存与主存不一致问题。对于单核CPU来说，处理比较简单，通常由一下两种方式：

- 通写法（Write Through）：每次CPU修改缓存内容，都会立即更新到内存中，也就意味着每次CPU写共享数据，都会导致总线事务。
- 写回法（Write BACK）：每次CPU修改了缓存数据，不会立即更新到内存，而是等到某个合适的机会才更新到内存中

**对于多核CPU来说，情况更为复杂**

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401051726579.webp)

多核CPU存在多个一级缓存，如何保证这些缓存一级内存之间的一致性？

在全面的两种方法外，还有两种操作

- 写失效：当一个CPU修改了数据，如果其他CPU有该数据，则通知为无效
- 写更新：当一个CPU修改了数据，如果其他CPU有该数据，则通知其更新数据

另外在CPU层面，提供了两种解决方案：

- 总线锁：在多CPU情况下，某个CPU对共享变量操作时，在总线上发出一个`#LOCK`信号，总线把CPU和内存中间的通信锁住了，其他CPU不能操作该内存地址的数据
- 缓存锁：降低了锁的粒度，基于缓存一致性协议来实现。

**缓存一致性协议需要满足一下两种特性**

- 写传播：一个处理器对某个内存位置所做的写操作，对其他处理器是可见的
- 写串行化：对同一内存单元的所有写操作都能串行化。即所有的处理器能以相同的次序看到这些写操作

对于写串行化：总线上任意时间只能出现一个CPU的写事件，多核并发的写事件会通过总线仲裁机制将其转换为串行化的写事件序列。

对于写传播：大致可以分为一下两种方式

- 嗅探：广播机制，即要监听总线上的所有活动
- 基于目录：点对点，总线事件只会发给感兴趣的CPU（借助directory）

> 我们经常提到的缓存一致性协议通常指的是MESI协议（各厂商的CPU有对应的缓存一致性协议，intel的是mesi协议，amd的是moesi协议）

## 3.MESI协议

按照上文的概念，可以这样看待MESI协议：

- 回写性
- 写失效
- 缓存锁
- 写传播+写串行化
- 嗅探机制

### 3.1四种状态

 MESI指的是缓存行的四种状态（Modified，Exclusive，Shared， Invalid），用两个bit表示

>  缓存行（Cache line）:缓存存储数据的单元。

| 状态                 | 描述                                                         |
| -------------------- | ------------------------------------------------------------ |
| M 已修改 (Modified)  | 已修改。缓存行与主存的值不同。如果别的 CPU 内核要读主存这块数据，该缓存行必须回写到主存，状态变为共享状态（S）。 |
| E 独占的 (Exclusive) | 独占的。缓存行只在当前缓存中，但和主存数据一致。当别的缓存读取它时，状态变为共享；当前写数据时，变为已修改状态（M）。 |
| S 共享的 (Shared)    | 当前CPU与其他CPU拥有相同数据，并与内存中数据一致             |
| I 无效的 (Invalid)   | 当前CPU数据失效，其他CPU数据可能有可能无，数据应从内存中读取，且当前CPU与内存数据不一致 |

### 3.2四种操作

- Local Read（LR）：当前 CPU 读操作
- Local Write（LW）：当前 CPU 写操作
- Remote Read（RR）：其他 CPU 读操作
- Remote Write（RW）：其他 CPU 写操作

### 3.3状态转换

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401051725338.webp)

[动态理解网站](https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm)

![image-20240105200909429](C:\Users\du jiachen\AppData\Roaming\Typora\typora-user-images\image-20240105200909429.png)

#### 3.3.1 Modified

- LR：当前 CPU 读操作，缓存中拥有最新数据，直接从缓存中读取，状态不变。
- LW：当前 CPU 写操作，直接修改当前 CPU 缓存数据，修改后仍拥有最新数据，状态不变。
- RR：其他 CPU 方式读操作，为了保证一致性，当前 CPU 将数据写回内存，随后 RR 使得其他 CPU 与当前 CPU 拥有相同数据，状态 改为 S。
- RW：其他 CPU 写操作，当前 CPU 将数据写回内存，随后 RW 将内存数据修改，当前 CPU 缓存状态改为 I。

#### 3.3.2 Exclusive

- LR：当前 CPU 读操作，状态不变。
- LW：当前 CPU 写操作，修改当前 CPU 缓存值，状态改为 M。
- RR：其他 CPU 读操作，两个 CPU 和内存中数据一致，状态改为 S。
- RW：其他 CPU 写操作，其他 CPU 数据为最新，当前 CPU 数据失效，状态改为 I。

#### 3.3.3 Shared

- LR：当前 CPU 读数据，状态不变
- LW：当前 CPU 写操作，并不会将数据立即写回内存，为了保证一致性，将状态修改为 M。
- RR：其他 CPU 读操作，因为多个 CPU 数据都与内存一致，状态不变。
- RW：其他 CPU 写操作，其他 CPU 数据为最新，当前 CPU 数据失效，状态改为 I。

#### 3.3.4 Invalid

- LR：当前 CPU 读操作，当前 CPU 缓存不可用，需要读内存。

- - 其他 CPU 无数据，当前 CPU 独享数据，状态改为 E。
  - 其他 CPU 有数据且状态为 S 、E，当前CPU 与其他 CPU 以及内存数据一致，状态修改为 S。
  - 其他 CPU 有数据且状态为 M, 其他 CPU 先将数据写回内存，随后当前 CPU 读数据，与其他 CPU 以及内存数据一致，状态改为 S。

- LW：当前 CPU 写操作，当前 CPU 缓存不可用，需要写内存。

- - 其他 CPU 无数据，只有当前 CPU 缓存有数据，且被修改与内存不一致，状态改为 M。
  - 其他 CPU 又数据且为 S、E，当前 CPU 缓存为最新且已修改，状态改为 M。
  - 其他 CPU 有数据且状态为 M, 其他 CPU 先将数据写回内存，随后当前 CPU 写数据，状态改为 M。

- RR：其他 CPU 读操作，与当前 CPU 缓存无关，状态不变。

- RW：其他 CPU 写操作，与当前 CPU 缓存无关，状态不变。

看到这里你可能会好奇，看起来这个协议没毛病啊？如果在 CPU 层面已经做好了约束，那么在 Java 内存模型里面为什么还有可见性和有序性问题呢？

## 4.MESI协议的问题与优化

在MESI中，依赖总线嗅探机制，整个过程是串行的，可能会发生阻塞。

1. 若 CPU0 发生 LW，首先需要发送一个 Invalidate 消息给到其他缓存了该数据的 CPU1。并且要等待 CPU1 的确认回执。CPU0 在这段时间内都会处于阻塞状态。

2. 对于 CPU1 发生 RW，需要失效缓存。当其高速缓存压力很大时，要求实时的处理失效事件也存在一定的困难，会有一定的延迟。

**这样CPU的性能并没有被压缩到极致**

### Store Buffer

如果CPU对某个数据进行写操作，且这个数据部在所有缓存里，那么CPU就会发送一个Read Invalidate消息去读取对应的数据，并让其他的缓存副本失效

**但是**，在发消息之后，到接收到所有响应消息，中间等待过程对于CPU来说是漫长的

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061152984.webp)

如何减少CPU等待消息的时间？

**store buffer就是这个作用**

它是CPU和缓存中间的一块结构

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061201866.webp)

CPU在写操作时，可以**不等待**其他CPU消息响应就直接写到store buffer，后续收到响应消息之后，再把store buffer里面的数据写入缓存行。

> **这样等待的过程可能会处理其他事件，这样却导致指令并未按顺序执行或者数据未及时更新，产生错误**

CPU读消息时，也会先判断store buffer里面有没有数据，如果存在，就优先使用store buffer里面的数据（这个机制，叫做“store forwarding”）。

从而提高了CPU的利用率，也能保证了在**同一**CPU，读写都能顺序执行。

注意，这里的读写顺序执行说的是**同一**CPU，因为store buffer的引入并不能保证多CPU全局顺序执行。

因为，store buffer 的引入并不能保证多 CPU 全局顺序执行。

我们看下面这个例子：

```c
// CPU0 执行
void foo() { 
    a = 1;
    b = 1;
}

// CPU1 执行
void bar() {
    while(b == 0) continue;
    assert(a == 1);
}
```

假设 CPU0 执行 foo 方法，CPU1 执行 bar 方法，如果在执行之前，缓存的情况是这样的：

1. CPU0 缓存了 b，因为独占，所以状态是 E。
2. CPU1 缓存了 a，因为独占，所以状态是 E。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061252997.webp)

那么，在有了 store buffer 之后，有可能出现这种情况（简化了与内存交互的过程）：

store buffer提升了性能（本处解释假设不存在invalidate queue，方便理解问题)，却引入了复杂性，考虑如下顺序：

1. cpu0执行a = 1指令，其cache中值是0，那么由于store buffer的引入，cpu0直接将a = 1写入了store buffer，不需要等待cpu1的信号响应就可以执行b = 1。
2. cpu0执行b = 1时，由于b在cpu0中的状态是exclusive独占（可以去参考文章看MESI协议），cpu0直接将b = 1写入了cpu 0 cache中，那么cpu1执行b != 1 成功，然后执行assert( a == 1)，由于cpu0需要等到cpu1响应完invalidate才将 a= 1写入cache中（目前还在store buffer中），所以cpu1读取到的任然是0，assert失败。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061347979.png)


 从图例可以看到第六步assert失败的核心原因在于，cpu0上缓存过b，所以cpu0执行b = 1k立马写入cache，然后线程B所在的cpu1执行while(b==0)迅速跳出，然后执行 a = 1，由于此时 a 还在cpu0的store buffer中（也类似于），所以导致assert失败。

那如何解决 store buffer 的引入带来的全局顺序性问题呢？

硬件设计师给开发者提供了内存屏障（memory-barrier）指令，我们只需要使用内存屏障将代码改造一下，在 a = 1 后面加上 smp_mb()，就能消除 store buffer 的引入带来的影响。

```c
// CPU0 执行
void foo() { 
    a = 1;
    smp_mb();
    b = 1;
}

// CPU1 执行
void bar() {
    while(b == 0) continue;
    assert(a == 1);
}
```

内存屏障是如何做到全局顺序性的呢？

> 大多数时候使用的是store buffer排队，这样效率较高

有两种方式，分别是**等 store buffer 生效**和**进 store buffer 排队**。

#### 等 store buffer 生效

等 store buffer 生效就是内存屏障后续的写必须等待 store buffer 里面的值都收到了对应的响应消息，都被写到缓存行里面。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061300342.gif)

#### 进 store buffer 排队

进 store buffer 排队就是内存屏障后续的写直接写到 store buffer 排队，等 store buffer 前面的写全部被写到缓存行。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061300368.gif)

从动图上可以看出，两种方式都需要等，但是**等 store buffer 生效**是在 CPU 等，而**进 store buffer 排队**是进 store buffer 等。

所以，**进 store buffer 排队**也会相对高效一些，大多数的系统采用的也是这种方式。

### Invalidate Queue

> 先不处理失效的消息，先返回响应，保存在队列中等待处理，减少另一个CPU等待时间

内存屏障能解决 store buffer 带来的全局顺序性问题。但有一个问题，store buffer 容量非常小，如果在其他 CPU 繁忙的时候响应消息的速度变慢，store buffer 会很容易地被填满，会直接的影响 CPU 的运行效率。

怎么办呢？

这个问题的根源是响应消息慢导致 store buffer 被填满，那能不能提高消息响应速度呢？

能！invalidate queue 出现了。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061414323.webp)

invalidate queue 的主要作用就是提高 invalidate 消息的响应速度。

有了 invalidate queue 之后，CPU 在收到 invalidate 消息时，可以先不讲对应的缓存行失效，而是将消息放入 invalidate queue，立即返回 Invalidate Acknowledge 消息，然后在要对外发送 invalidate 消息时，先检查 invalidate queue 中有无该缓存行的 Invalidate 消息，如果有的话这个时候才处理 Invalidate 消息。

invalidate queue 虽然能加快 invalidate 消息的响应速度，但是也带了全局顺序性问题，这个和 store buffer 带来的全局性问题类似。

看下面这个例子：

```c
c复制代码// CPU0 执行
void foo() { 
    a = 1;
    smp_mb();
    b = 1;
}

// CPU1 执行
void bar() {
    while(b == 0) continue;
    assert(a == 1);
}
```

上面这段代码，还是假设 CPU0 执行 foo 方法，CPU1 执行 bar 方法，如果在执行之前，缓存的情况是这样的：

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061414710.webp)

那么，在有了 invalidate queue 之后，有可能出现这种执行情况：

1. CPU0 执行 a=1。对应的缓存行在 cpu0 的缓存中是只读的，所以 cpu0 把新值 a=1 放在了它的 store buffer 中，并发送了一个 invalidate 消息，以便从 cpu1 的 cache 中刷新对应的缓存行。
2. 当(b==0)继续执行时，CPU1 执行，但是包含 b 的缓存行不在它的缓存中。因此，它发送一个 read 消息。
3. CPU0 执行 b=1。因为已经缓存了这个缓存行，所以直接更新缓存行，将 b=0 更新成 b=1。
4. CPU0 接收到 read 消息，并将包含 b 的缓存行发送给 CPU1，同时 b 所在缓存行的状态改成 S。
5. CPU1 接收到 a 的 invalidate 消息，将其放入自己的 invalidate 队列，并向 CPU0 发送一个 invalidate 确认消息。注意，原来的值“a”仍然保存在 CPU1 的缓存中。
6. CPU1 接收到包含 b 的缓存行，并将其写到它的缓存中。
7. CPU1 现在可以在(b==0)继续时完成执行，因为它发现 b 的值是 1，它继续执行下一条语句。
8. CPU1 执行 assert(a==1)，由于原来的值 a 仍然在 CPU1 的缓存中，所以断言失败了。
9. cpu1 处理队列中 invalidate 的消息，并从自己的 cache 中使包含 a 的 cache 行失效。但是已经太迟了。

从这个例子可以看出，在引入 invalidate queue 之后，全局顺序性又得不到保障了。

怎么解决呢，和 store buffer 的解决办法是一样的，用**内存屏障**改造代码：

```c
// CPU0 执行
void foo() { 
    a = 1;
    smp_mb();
    b = 1;
}

// CPU1 执行
void bar() {
    while(b == 0) continue;
    smp_mb();
    assert(a == 1);
}
```

改造之后的运行过程不做过多表述，但总结来说就是内存屏障可以解决 invalidate queue 带来的全局顺序性问题。

>  内存屏障会先把Invalidate queue中的数据处理掉之后，在执行屏障后的“读取操作”

### 内存屏障和Lock指令

#### 内存屏障

内存屏障的作用：处理store buffer和invalidate queue，保证全局顺序性。

但很多情况下，只需处理store buffer和invalidate queue中的一个即可，所以很多系统将内存屏障细分为读屏障和写屏障

读屏障用于处理invalidate queue，写屏障用于处理store buffer

#### Lock指令

 volatile 关键字的底层实现是 lock 前缀指令。

lock 前缀指令和内存屏障到底有什么关系呢？

我认为是没有什么关系的。

只不过 lock 前缀指令一部分功能能达到内存屏障的效果罢了。

这一点在《IA-32 架构软件开发人员手册》上也能找到对应的描述。

![img](https://cdn.jsdelivr.net/gh/ddddjc/djcPicture@master/202401061455227.webp)

手册上给 lock 前缀指令的定义是总线锁，也就是 lock 前缀指令是通过锁住总线保证可见性和禁止指令重排序的。

虽然“总线锁”的说法过于老旧了，现在的系统更多的是“锁缓存行”。但我想表达的是，lock 前缀指令的核心思想还是“锁”，这和内存屏障有着本质的区别。

## 总结

本文对一些没有基础的同学来说，理解起来会稍微吃力一点，所以我们总结一下全文的一个思路，应付应付普通面试是没什么问题的。

1. 因为内存的速度和 CPU 匹配不上，所以在内存和 CPU 之间加了多级缓存。
2. 单核 CPU 独享不会出现数据不一致的问题，但是多核情况下会有缓存一致性问题。
3. 缓存一致性协议就是为了解决多组缓存导致的缓存一致性问题。
4. 缓存一致性协议有两种实现方式，一个是基于目录的，一个是基于总线嗅探的。
5. 基于目录的方式延迟高，但是占用总线流量小，适合 CPU 核数多的系统。
6. 基于总线嗅探的方式延迟低，但是占用总线流量大，适合 CPU 核数小的系统。
7. 常见的 MESI 协议就是基于总线嗅探实现的。
8. MESI 解决了缓存一致性问题，但是还是不能将 CPU 性能压榨到极致。
9. 为了进一步压榨 CPU，所以引入了 store buffer 和 invalidate queue。
10. store buffer 和 invalidate queue 的引入导致不满足全局有序，所以需要有写屏障和读屏障。
11. X86 架构下的读屏障指令是 lfenc，写屏障指令是 sfence，读写屏障指令是 mfence。
12. lock 前缀指令直接锁缓存行，也能达到内存屏障的效果。
13. x86 架构下，volatile 的底层实现就是 lock 前缀指令。
14. JMM 是一个模型，是一个便于 Java 开发人员开发的抽象模型。
15. 缓存性一致性协议是为了解决 CPU 多核系统下的数据一致性问题，是一个客观存在的东西，不需要去触发。
16. **JMM 和缓存一致性协议没有一毛钱关系。**
17. **JMM 和 MESI 没有一毛钱关系。**